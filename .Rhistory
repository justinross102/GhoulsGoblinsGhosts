indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
train
test <- all_games[-indices, ] %>%
select(-Outcome)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
train
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
prepped <- prep(my_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked <- bake(prepped, new_data = train) # should have 112 columns
baked
view(baked)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
pen_bestTune
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_pen_wf <- rand_forest_workflow %>%
finalize_workflow(pen_bestTune) %>%
fit(data = train)
predictions <- final_pen_wf %>%
predict(new_data = test,
type = "prob")
predictions
matching_rows <- all_games[all_games$Date %in% test$Date, ]
# ROC curve and AUC for the training set
roc_train <- roc(y_train, pred_train)
view(test)
matching_rows <- all_games[all_games$Date %in% test$Date, ]
view(matching_rows)
matching_rows <- matching_rows[-2, ]
view(matching_rows)
matching_rows <- matching_rows[-43, ]
view(matching_rows)
install.packages("pROC")
library(pROC)
# ROC curve and AUC for the training set
roc_train <- roc(train$Outcome, predictions$.pred_W)
# ROC curve and AUC for the training set
roc_train <- roc(test$Outcome, predictions$.pred_W)
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# find out how good it is
matching_rows <- all_games[all_games$Date %in% test$Date, ]
matching_rows <- matching_rows[-2, ]
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# ROC curve and AUC for the training set
roc_train <- roc(matching_rows$Outcome, predictions$.pred_W)
auc_train <- auc(roc_train)
# Print AUC values
cat("Training AUC:", auc_train, "\n")
cat("Testing AUC:", auc_test, "\n")
# Plot ROC curves
plot(roc_train, main = "ROC Curve - Training Set", col = "blue")
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) %>%  # target encoding (must be 2-factor)
step_nzv(all_nominal_predictors())
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
library(tidyverse)
library(rvest)
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
head(162) %>%
select(-c(1,2))
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162) %>%
select(-c(1,2))
for (col in names(batting)) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = if_else(Location == "@", "Away", "Home"),
D_N = if_else(D_N == "D", "Day", "Night"),
Date = as.Date(Date, format = "%A, %b %d")) %>%
select(c(2,5,18,6,7))
merged_data <- bind_cols(defense, batting)
all_games <- bind_cols(phillies_games, merged_data)
view(all_games)
colnames(all_games)
split_index <- initial_split(all_games, prop = 0.8)
# predictions -------------------------------------------------------------
library(tidymodels)
library(embed) # for target encoding
split_index <- initial_split(all_games, prop = 0.8)
train_data <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
rf_recipe <- recipe(formula = as.formula(paste(outcome_var, "~ .")), data = train_data) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
prepped <- prep(target_encoding_recipe)
prepped <- prep(rf_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
library(tidyverse)
library(nycflights13)
flights
dat <- flights
dat$year <- 'Justin'
dat
library(RMySQL)
library(tidyverse)
library(vroom)
args <- commandArgs(TRUE)
form <- 'A'
mydb <- dbConnect(MySQL(), user = 'stat226', password = 'cougars19', dbname = 'Stat226', host = 'statdb.byu.edu')
query1 <- paste("SELECT s.StudentID, s.Score, d.Domain_num
FROM Students s, Domain d
WHERE (s.Form = d.Form) AND (s.Qnum = d.Qnum)
AND s.FORM =", shQuote(form),
"ORDER BY StudentID")
result1 <- dbSendQuery(mydb, query1)
data1 <- fetch(result1, n=-1)
# Find out which Domain_num has the lowest mean score. You will
# answer a question about this on a quiz but dont write this table to
# SQL_Final (In this scenario you are the professor and you want to find
# out which topic you need to teach the students better.) (5 points)
data1 %>%
group_by(Domain_num) %>%
summarise(StudentID = first(StudentID), mean_Score = mean(Score)) %>%
arrange(mean_Score)
query2 <- paste("SELECT s.StudentID, SUM(Score) AS Score, SUM(Score)/150 AS Percentages
FROM Students s, Domain d
WHERE (s.Form = d.Form) AND (s.Qnum = d.Qnum)
AND s.FORM =", shQuote(form),
"GROUP BY s.StudentID")
result2 <- dbSendQuery(mydb, query2)
data2 <- fetch(result2, n=-1)
auto_grade <- function(table) {
table$Grade <- 0
for (i in 1:nrow(table)) {
if (table$Percentages[i] >= 0.90 & table$Percentages[i] <= 1.0) {
table$Grade[i] <- 'A'
} else if (table$Percentages[i] >= 0.80 & table$Percentages[i] < 0.90) {
table$Grade[i] <- 'B'
} else if (table$Percentages[i] >= 0.70 & table$Percentages[i] < 0.80) {
table$Grade[i] <- 'C'
} else if (table$Percentages[i] >= 0.60 & table$Percentages[i] < 0.70) {
table$Grade[i] <- 'D'
} else {
table$Grade[i] <- 'F'
}
}
return(table)
}
# add letter grade column via auto_grade function
data2 <- auto_grade(data2)
# add curved percent column
data2$Curved_Percent <- 0
# calculate curved grades
for (i in 1:nrow(data2)){
data2$Curved_Percent[i] <- data2$Percentages[i] / max(data2$Percentages)
}
# function to calculate curved grades
auto_curve <- function(table) {
table$Curved_Grade <- 0
for (i in 1:nrow(table)) {
if (table$Curved_Percent[i] >= 0.90 & table$Curved_Percent[i] <= 1.0) {
table$Curved_Grade[i] <- 'A'
} else if (table$Curved_Percent[i] >= 0.80 & table$Curved_Percent[i] < 0.90) {
table$Curved_Grade[i] <- 'B'
} else if (table$Curved_Percent[i] >= 0.70 & table$Curved_Percent[i] < 0.80) {
table$Curved_Grade[i] <- 'C'
} else if (table$Curved_Percent[i] >= 0.60 & table$Curved_Percent[i] < 0.70) {
table$Curved_Grade[i] <- 'D'
} else {
table$Curved_Grade[i] <- 'F'
}
}
return(table)
}
data2 <- auto_curve(data2)
head(data2)
mydb2 <- dbConnect(MySQL(), user = 'root', password = 'Johnwilliams102', dbname = 'stats286_sqlfinal', host = 'localhost')
dbWriteTable(mydb2, name = "Final_Results", value = data2, row.names=F, overwrite = T)
dbDisconnect(mydb)
dbDisconnect(mydb2)
vroom_write(data2, file = "form_results.txt", delim = " ")
# load necessary libraries
library(tidyverse)
library(tidymodels)
library(vroom) # reading and writing file
library(embed) # target encoding
library(discrim) # naive bayes
library(keras)
library(tensorflow)
predict_and_format <- function(model, newdata, filename){
predictions <- predict(model, new_data = newdata)
submission <- predictions %>%
mutate(id = test$id) %>%
rename("type" = ".pred_class") %>%
select(2,1)
vroom_write(submission, filename, delim = ',')
}
basic_recipe <- recipe(type ~ ., train) %>%
step_rm(id) %>%
step_normalize(all_numeric_predictors())
setwd("~/Documents/BYU/stat348/GhoulsGoblinsGhosts")
train <- vroom("train.csv") %>%
mutate(type = as.factor(type))
test <- vroom("test.csv") # already has 'type' removed
basic_recipe <- recipe(type ~ ., train) %>%
step_rm(id) %>%
step_normalize(all_numeric_predictors())
nb_mod <- naive_Bayes(Laplace = tune(),
smoothness = tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes")
nb_wf <- workflow() %>%
add_recipe(basic_recipe) %>%
add_model(nb_mod)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
nb_folds <- vfold_cv(train, v = 5, repeats = 2)
CV_results <- nb_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(accuracy)) # f_meas, sens, recall, spec, precision, accuracy, roc_auc
nb_bestTune <- CV_results %>%
select_best("accuracy")
final_nb_wf <- nb_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
setwd("~/Documents/BYU/stat348/GhoulsGoblinsGhosts")
predict_and_format(final_nb_wf, test, "naive_bayes_preds.csv")
basic_recipe <- recipe(type ~ ., train) %>%
step_rm(id) %>%
step_dummy(color)
nb_wf <- workflow() %>%
add_recipe(basic_recipe) %>%
add_model(nb_mod)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
nb_folds <- vfold_cv(train, v = 5, repeats = 2)
CV_results <- nb_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(accuracy)) # f_meas, sens, recall, spec, precision, accuracy, roc_auc
nb_bestTune <- CV_results %>%
select_best("accuracy")
final_nb_wf <- nb_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "naive_bayes_preds.csv")
nn_model <- mlp(hidden_units = tune(),
epochs = 50,
activation = "relu") %>%
set_engine("keras", verbose = 0) %>%
set_mode("classification")
nn_recipe <- recipe(type ~ ., data = train) %>%
update_role(id, new_role="id") %>%
step_mutate(color = as.factor(color)) %>%  # Turn 'color' into a factor
step_dummy(color, one_hot = TRUE) %>% # dummy encode 'color'
step_range(all_numeric_predictors(), min=0, max=1) # scale to [0,1]
nn_wf <- workflow() %>%
add_recipe(nn_recipe) %>%
add_model(nn_model)
nn_tuneGrid <- grid_regular("hidden_units", range = c(1, 5), levels = 5)
nn_tuneGrid <- grid_regular(hidden_units(range = c(1, 5)), levels = 5)
nn_folds <- vfold_cv(train, v = 5, repeats = 1)
CV_results <- tune_grid(nn_wf,
resamples = nn_folds,
grid = nn_tuneGrid,
metrics = metric_set(accuracy))
