show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
train
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
prepped <- prep(my_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked <- bake(prepped, new_data = train) # should have 112 columns
baked
view(baked)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
pen_bestTune
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_pen_wf <- rand_forest_workflow %>%
finalize_workflow(pen_bestTune) %>%
fit(data = train)
predictions <- final_pen_wf %>%
predict(new_data = test,
type = "prob")
predictions
matching_rows <- all_games[all_games$Date %in% test$Date, ]
# ROC curve and AUC for the training set
roc_train <- roc(y_train, pred_train)
view(test)
matching_rows <- all_games[all_games$Date %in% test$Date, ]
view(matching_rows)
matching_rows <- matching_rows[-2, ]
view(matching_rows)
matching_rows <- matching_rows[-43, ]
view(matching_rows)
install.packages("pROC")
library(pROC)
# ROC curve and AUC for the training set
roc_train <- roc(train$Outcome, predictions$.pred_W)
# ROC curve and AUC for the training set
roc_train <- roc(test$Outcome, predictions$.pred_W)
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# find out how good it is
matching_rows <- all_games[all_games$Date %in% test$Date, ]
matching_rows <- matching_rows[-2, ]
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# ROC curve and AUC for the training set
roc_train <- roc(matching_rows$Outcome, predictions$.pred_W)
auc_train <- auc(roc_train)
# Print AUC values
cat("Training AUC:", auc_train, "\n")
cat("Testing AUC:", auc_test, "\n")
# Plot ROC curves
plot(roc_train, main = "ROC Curve - Training Set", col = "blue")
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) %>%  # target encoding (must be 2-factor)
step_nzv(all_nominal_predictors())
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
library(tidyverse)
library(rvest)
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
head(162) %>%
select(-c(1,2))
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162) %>%
select(-c(1,2))
for (col in names(batting)) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = if_else(Location == "@", "Away", "Home"),
D_N = if_else(D_N == "D", "Day", "Night"),
Date = as.Date(Date, format = "%A, %b %d")) %>%
select(c(2,5,18,6,7))
merged_data <- bind_cols(defense, batting)
all_games <- bind_cols(phillies_games, merged_data)
view(all_games)
colnames(all_games)
split_index <- initial_split(all_games, prop = 0.8)
# predictions -------------------------------------------------------------
library(tidymodels)
library(embed) # for target encoding
split_index <- initial_split(all_games, prop = 0.8)
train_data <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
rf_recipe <- recipe(formula = as.formula(paste(outcome_var, "~ .")), data = train_data) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
prepped <- prep(target_encoding_recipe)
prepped <- prep(rf_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
library(tidyverse)
library(nycflights13)
flights
dat <- flights
dat$year <- 'Justin'
dat
library(RMySQL)
library(tidyverse)
library(vroom)
args <- commandArgs(TRUE)
form <- 'A'
mydb <- dbConnect(MySQL(), user = 'stat226', password = 'cougars19', dbname = 'Stat226', host = 'statdb.byu.edu')
query1 <- paste("SELECT s.StudentID, s.Score, d.Domain_num
FROM Students s, Domain d
WHERE (s.Form = d.Form) AND (s.Qnum = d.Qnum)
AND s.FORM =", shQuote(form),
"ORDER BY StudentID")
result1 <- dbSendQuery(mydb, query1)
data1 <- fetch(result1, n=-1)
# Find out which Domain_num has the lowest mean score. You will
# answer a question about this on a quiz but dont write this table to
# SQL_Final (In this scenario you are the professor and you want to find
# out which topic you need to teach the students better.) (5 points)
data1 %>%
group_by(Domain_num) %>%
summarise(StudentID = first(StudentID), mean_Score = mean(Score)) %>%
arrange(mean_Score)
query2 <- paste("SELECT s.StudentID, SUM(Score) AS Score, SUM(Score)/150 AS Percentages
FROM Students s, Domain d
WHERE (s.Form = d.Form) AND (s.Qnum = d.Qnum)
AND s.FORM =", shQuote(form),
"GROUP BY s.StudentID")
result2 <- dbSendQuery(mydb, query2)
data2 <- fetch(result2, n=-1)
auto_grade <- function(table) {
table$Grade <- 0
for (i in 1:nrow(table)) {
if (table$Percentages[i] >= 0.90 & table$Percentages[i] <= 1.0) {
table$Grade[i] <- 'A'
} else if (table$Percentages[i] >= 0.80 & table$Percentages[i] < 0.90) {
table$Grade[i] <- 'B'
} else if (table$Percentages[i] >= 0.70 & table$Percentages[i] < 0.80) {
table$Grade[i] <- 'C'
} else if (table$Percentages[i] >= 0.60 & table$Percentages[i] < 0.70) {
table$Grade[i] <- 'D'
} else {
table$Grade[i] <- 'F'
}
}
return(table)
}
# add letter grade column via auto_grade function
data2 <- auto_grade(data2)
# add curved percent column
data2$Curved_Percent <- 0
# calculate curved grades
for (i in 1:nrow(data2)){
data2$Curved_Percent[i] <- data2$Percentages[i] / max(data2$Percentages)
}
# function to calculate curved grades
auto_curve <- function(table) {
table$Curved_Grade <- 0
for (i in 1:nrow(table)) {
if (table$Curved_Percent[i] >= 0.90 & table$Curved_Percent[i] <= 1.0) {
table$Curved_Grade[i] <- 'A'
} else if (table$Curved_Percent[i] >= 0.80 & table$Curved_Percent[i] < 0.90) {
table$Curved_Grade[i] <- 'B'
} else if (table$Curved_Percent[i] >= 0.70 & table$Curved_Percent[i] < 0.80) {
table$Curved_Grade[i] <- 'C'
} else if (table$Curved_Percent[i] >= 0.60 & table$Curved_Percent[i] < 0.70) {
table$Curved_Grade[i] <- 'D'
} else {
table$Curved_Grade[i] <- 'F'
}
}
return(table)
}
data2 <- auto_curve(data2)
head(data2)
mydb2 <- dbConnect(MySQL(), user = 'root', password = 'Johnwilliams102', dbname = 'stats286_sqlfinal', host = 'localhost')
dbWriteTable(mydb2, name = "Final_Results", value = data2, row.names=F, overwrite = T)
dbDisconnect(mydb)
dbDisconnect(mydb2)
vroom_write(data2, file = "form_results.txt", delim = " ")
# load necessary libraries
library(tidyverse)
library(tidymodels)
library(vroom) # reading and writing file
library(embed) # target encoding
library(discrim) # naive bayes
library(keras)
library(tensorflow)
setwd("~/Documents/BYU/stat348/GhoulsGoblinsGhosts")
train <- vroom("train.csv") %>%
mutate(type = as.factor(type))
test <- vroom("test.csv") # already has 'type' removed
missSet <- vroom("trainWithMissingValues.csv")
missSet <- vroom("trainWithMissingValues.csv")
# check NAs
na_count_train <- colSums(is.na(missSet))
na_count_test <- colSums(is.na(missSet))
print(na_count_train)
print(na_count_test)
na_count_test <- colSums(is.na(test))
print(na_count_train)
print(na_count_test)
missSet
columns_with_missing_values <- colnames(missSet)[apply(is.na(missSet), 2, any)]
print(columns_with_missing_values)
missing_recipe <- recipe(type ~ ., missSet) %>%
step_impute_mean(bone_length, rotting_flesh, hair_length)
prepped_recipe <- prep(missing_recipe)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
columns_with_missing_values <- colnames(missSet)[apply(is.na(missSet), 2, any)]
print(columns_with_missing_values)
missing_recipe <- recipe(type ~ ., missSet) %>%
step_impute_median(bone_length, rotting_flesh, hair_length)
prepped_recipe <- prep(missing_recipe)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
missing_recipe <- recipe(type ~ ., missSet) %>%
step_impute_mean(bone_length, rotting_flesh, hair_length)
prepped_recipe <- prep(missing_recipe)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
missing_recipe <- recipe(type ~ ., missSet) %>%
step_impute_mean(bone_length) %>%
step_impute_mean(rotting_flesh) %>%
step_impute_mean(hair_length)
prepped_recipe <- prep(missing_recipe)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
missing_recipe <- recipe(type ~ ., missSet) %>%
step_impute_mean(bone_length, rotting_flesh, hair_length)
prepped_recipe <- prep(missing_recipe)
baked <- bake(prepped_recipe, new_data = missSet)
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul, color), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
baked
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(c(has_soul, color)), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
baked
step_impute_knn(var, impute_with = imp_vars(...), neighbors=)
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(color), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(color), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(color), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
baked
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(all_predictors()), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(all_predictors), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(all_predictors), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
baked
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(all_predictors()), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(all_predictors), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(all_predictors), neighbors=10)
prepped_recipe <- prep(second_try)
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(all_predictors()), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(all_predictors()), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(all_predictors()), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
second_try <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
baked
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
knn_impute <- recipe(type ~ ., missSet) %>%
step_impute_knn(bone_length, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(rotting_flesh, impute_with = imp_vars(has_soul), neighbors=10) %>%
step_impute_knn(hair_length, impute_with = imp_vars(has_soul), neighbors=10)
prepped_recipe <- prep(second_try)
baked <- bake(prepped_recipe, new_data = missSet)
rmse_vec(train[is.na(missSet)], baked[is.na(missSet)])
