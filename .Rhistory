merged_data <- as_tibble(inner_join(phillies_games, defense, by = c("Date", "Opp")))
merged_data <- as_tibble(inner_join(phillies_games, defense, by = c("Date", "Opp"), relationship = "many-to-many"))
merged_data
library(tidyverse)
library(rvest)
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
head(162)
defense
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162)
for (col in names(batting)[-1]) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162) %>%
select(-c(1,2))
for (col in names(batting)) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162)
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162)
for (col in names(batting)[-1]) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162) %>%
select(-c(1,2))
for (col in names(batting)) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
head(162) %>%
select(-c(1,2))
defense
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = if_else(Location == "@", "Away", "Home"),
D_N = if_else(D_N == "D", "Day", "Night"),
Date = as.Date(Date, format = "%A, %b %d")) %>%
select(c(2,5,18,6,7))
phillies_games
merged_data <- bind_cols(defense, batting)
view(merged_data)
merged_data
all_games <- bind_cols(phillies_games, merged_data)
view(all_games)
all_games
# predictions -------------------------------------------------------------
library(tidymodels)
library(embed) # for target encoding
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
train
test <- all_games[-indices, ] %>%
select(-Outcome)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
step_dummy(all_nominal_predictors())  # dummy variable encoding
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
train
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) %>% # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# Generate random indices for train and test sets
indices <- sample(1:nrow(all_games), size = 0.7 * nrow(all_games))
# Create training and testing sets
train <- all_games[indices, ] %>%
mutate(Outcome = as.factor(Outcome))
test <- all_games[-indices, ] %>%
select(-Outcome)
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
my_recipe <- recipe(Outcome ~ ., data = train) %>%
step_date(Date, features="dow") %>% # pull out individual variables from datetime
step_date(Date, features="month") %>%
step_rm(Date) %>% # don't need it anymore
step_mutate_at(all_nominal_predictors(), fn = factor) # turn all nominal features into factors
rand_forest_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
prepped <- prep(my_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked <- bake(prepped, new_data = train) # should have 112 columns
baked
view(baked)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
pen_bestTune
## Find Best Tuning Parameters
pen_bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_pen_wf <- rand_forest_workflow %>%
finalize_workflow(pen_bestTune) %>%
fit(data = train)
predictions <- final_pen_wf %>%
predict(new_data = test,
type = "prob")
predictions
matching_rows <- all_games[all_games$Date %in% test$Date, ]
# ROC curve and AUC for the training set
roc_train <- roc(y_train, pred_train)
view(test)
matching_rows <- all_games[all_games$Date %in% test$Date, ]
view(matching_rows)
matching_rows <- matching_rows[-2, ]
view(matching_rows)
matching_rows <- matching_rows[-43, ]
view(matching_rows)
install.packages("pROC")
library(pROC)
# ROC curve and AUC for the training set
roc_train <- roc(train$Outcome, predictions$.pred_W)
# ROC curve and AUC for the training set
roc_train <- roc(test$Outcome, predictions$.pred_W)
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# find out how good it is
matching_rows <- all_games[all_games$Date %in% test$Date, ]
matching_rows <- matching_rows[-2, ]
matching_rows <- matching_rows[-43, ] %>%
mutate(Outcome = as.factor(Outcome))
# ROC curve and AUC for the training set
roc_train <- roc(matching_rows$Outcome, predictions$.pred_W)
auc_train <- auc(roc_train)
# Print AUC values
cat("Training AUC:", auc_train, "\n")
cat("Testing AUC:", auc_test, "\n")
# Plot ROC curves
plot(roc_train, main = "ROC Curve - Training Set", col = "blue")
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) %>%  # target encoding (must be 2-factor)
step_nzv(all_nominal_predictors())
prepped <- prep(target_encoding_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
library(tidyverse)
library(rvest)
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
head(162) %>%
select(-c(1,2))
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
head(162) %>%
select(-c(1,2))
for (col in names(batting)) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = if_else(Location == "@", "Away", "Home"),
D_N = if_else(D_N == "D", "Day", "Night"),
Date = as.Date(Date, format = "%A, %b %d")) %>%
select(c(2,5,18,6,7))
merged_data <- bind_cols(defense, batting)
all_games <- bind_cols(phillies_games, merged_data)
view(all_games)
colnames(all_games)
split_index <- initial_split(all_games, prop = 0.8)
# predictions -------------------------------------------------------------
library(tidymodels)
library(embed) # for target encoding
split_index <- initial_split(all_games, prop = 0.8)
train_data <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
split_index <- initial_split(all_games, prop = 0.8)
train <- training(split_index) %>%
mutate(Outcome = as.factor(Outcome))
test_ <- testing(split_index) %>%
select(-Outcome)
# Create a recipe
outcome_var <- "Outcome"
rf_recipe <- recipe(formula = paste(outcome_var, "~ ."), data = train) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
rf_recipe <- recipe(formula = as.formula(paste(outcome_var, "~ .")), data = train_data) %>%
step_date(Date) %>%
step_dummy(all_nominal(), -all_outcomes())
# model
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
prepped <- prep(target_encoding_recipe)
prepped <- prep(rf_recipe)
baked <- bake(prepped, new_data = train) # should have 112 columns
view(baked)
rand_forest_workflow <- workflow() %>%
add_recipe(rf_recipe) %>%
add_model(rand_forest_mod)
# tuning grid
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
show_notes(.Last.tune.result)
library(tidyverse)
library(nycflights13)
flights
dat <- flights
dat$year <- 'Justin'
dat
# load necessary libraries
library(tidyverse)
library(tidymodels)
library(vroom) # reading and writing file
library(embed) # target encoding
library(discrim) # naive bayes
setwd("~/Documents/BYU/stat348/GhoulsGoblinsGhosts")
train <- vroom("train.csv") %>%
mutate(type = as.factor(type))
test <- vroom("test.csv") # already has 'type' removed
predict_and_format <- function(model, newdata, filename){
predictions <- predict(model, new_data = newdata)
submission <- predictions %>%
mutate(id = test$id) %>%
rename("type" = ".pred_class") %>%
select(2,1)
vroom_write(submission, filename, delim = ',')
}
basic_recipe <- recipe(type ~ ., train) %>%
step_rm(id) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(color)
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_workflow <- workflow() %>%
add_recipe(basic_recipe) %>%
add_model(knn_model)
# cross validation
knn_tuning_grid <- grid_regular(neighbors(),
levels = 5)
knn_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- knn_workflow %>%
tune_grid(resamples = knn_folds,
grid = knn_tuning_grid,
metrics = metric_set(roc_auc))
## Run the CV
CV_results <- knn_workflow %>%
tune_grid(resamples = knn_folds,
grid = knn_tuning_grid,
metrics = metric_set(accuracy))
knn_bestTune <- CV_results %>%
select_best("accuracy")
# finalize workflow
final_knn_wf <- knn_workflow %>%
finalize_workflow(knn_bestTune) %>%
fit(data = train)
predict_and_format(final_knn_wf, test, "./knn_predictions.csv")
